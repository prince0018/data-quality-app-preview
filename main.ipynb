{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Item Purchased</th>\n",
       "      <th>Category</th>\n",
       "      <th>Purchase Amount (USD)</th>\n",
       "      <th>Review Rating</th>\n",
       "      <th>Subscription Status</th>\n",
       "      <th>Payment Method</th>\n",
       "      <th>Discount Applied</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2471</th>\n",
       "      <td>2472</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Sandals</td>\n",
       "      <td>Footwear</td>\n",
       "      <td>83</td>\n",
       "      <td>4.3</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>Skirt</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>26</td>\n",
       "      <td>3.9</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2791</th>\n",
       "      <td>2792</td>\n",
       "      <td>43.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Gloves</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>60</td>\n",
       "      <td>2.8</td>\n",
       "      <td>No</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>2998</td>\n",
       "      <td>41.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>621</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Backpack</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>89</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Yes</td>\n",
       "      <td>PayPal</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>631</td>\n",
       "      <td>41.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Jewelry</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>94</td>\n",
       "      <td>4.3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2267</th>\n",
       "      <td>2268</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gloves</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>49</td>\n",
       "      <td>3.8</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1787</th>\n",
       "      <td>1788</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>Sweater</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>Bank Transfer</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1951</th>\n",
       "      <td>1952</td>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gloves</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>Bank Transfer</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2425</th>\n",
       "      <td>2426</td>\n",
       "      <td>58.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Footwear</td>\n",
       "      <td>49</td>\n",
       "      <td>3.0</td>\n",
       "      <td>No</td>\n",
       "      <td>Venmo</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Customer ID   Age  Gender Item Purchased     Category  \\\n",
       "2471         2472  30.0    Male        Sandals     Footwear   \n",
       "2014         2015   NaN    Male          Skirt     Clothing   \n",
       "2791         2792  43.0  Female         Gloves  Accessories   \n",
       "2997         2998  41.0  Female            NaN     Clothing   \n",
       "620           621  33.0    Male       Backpack  Accessories   \n",
       "630           631  41.0    Male        Jewelry  Accessories   \n",
       "2267         2268  32.0     NaN         Gloves  Accessories   \n",
       "1787         1788   NaN    Male        Sweater     Clothing   \n",
       "1951         1952  33.0     NaN         Gloves  Accessories   \n",
       "2425         2426  58.0    Male            NaN     Footwear   \n",
       "\n",
       "      Purchase Amount (USD)  Review Rating Subscription Status Payment Method  \\\n",
       "2471                     83            4.3                  No            NaN   \n",
       "2014                     26            3.9                  No            NaN   \n",
       "2791                     60            2.8                  No    Credit Card   \n",
       "2997                     40            NaN                  No            NaN   \n",
       "620                      89            3.7                 Yes         PayPal   \n",
       "630                      94            4.3                 Yes            NaN   \n",
       "2267                     49            3.8                  No            NaN   \n",
       "1787                     38            NaN                  No  Bank Transfer   \n",
       "1951                     53            NaN                  No  Bank Transfer   \n",
       "2425                     49            3.0                  No          Venmo   \n",
       "\n",
       "     Discount Applied  \n",
       "2471               No  \n",
       "2014               No  \n",
       "2791               No  \n",
       "2997               No  \n",
       "620               Yes  \n",
       "630               Yes  \n",
       "2267               No  \n",
       "1787               No  \n",
       "1951               No  \n",
       "2425               No  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "data_description = \"The Dataset offers valuable insights into consumer shopping behavior and purchasing patterns.\"\n",
    "data=pd.read_csv('tabular_data.csv')\n",
    "sample_data=data.sample(n=10)\n",
    "sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3900 entries, 0 to 3899\n",
      "Data columns (total 10 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Customer ID            3900 non-null   int64  \n",
      " 1   Age                    3510 non-null   object \n",
      " 2   Gender                 3120 non-null   object \n",
      " 3   Item Purchased         3315 non-null   object \n",
      " 4   Category               3900 non-null   object \n",
      " 5   Purchase Amount (USD)  3900 non-null   int64  \n",
      " 6   Review Rating          2730 non-null   float64\n",
      " 7   Subscription Status    3900 non-null   object \n",
      " 8   Payment Method         2925 non-null   object \n",
      " 9   Discount Applied       3900 non-null   object \n",
      "dtypes: float64(1), int64(2), object(7)\n",
      "memory usage: 304.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Item Purchased</th>\n",
       "      <th>Category</th>\n",
       "      <th>Purchase Amount (USD)</th>\n",
       "      <th>Review Rating</th>\n",
       "      <th>Subscription Status</th>\n",
       "      <th>Payment Method</th>\n",
       "      <th>Discount Applied</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>Blouse</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>53</td>\n",
       "      <td>3.1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>19.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Bank Transfer</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jeans</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Cash</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Sandals</td>\n",
       "      <td>45</td>\n",
       "      <td>90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>PayPal</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>45.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Blouse</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>49</td>\n",
       "      <td>2.7</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Cash</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Customer ID   Age Gender Item Purchased  Category  Purchase Amount (USD)  \\\n",
       "0            1   NaN   Male         Blouse  Clothing                     53   \n",
       "1            2  19.0   Male            NaN  Clothing                     64   \n",
       "2            3   NaN    NaN          Jeans  Clothing                     73   \n",
       "3            4  21.0   Male        Sandals        45                     90   \n",
       "4            5  45.0    NaN         Blouse  Clothing                     49   \n",
       "\n",
       "   Review Rating Subscription Status Payment Method Discount Applied  \n",
       "0            3.1                 Yes    Credit Card              Yes  \n",
       "1            NaN                 Yes  Bank Transfer              Yes  \n",
       "2            NaN                 Yes           Cash              Yes  \n",
       "3            NaN                 Yes         PayPal              Yes  \n",
       "4            2.7                 Yes           Cash              Yes  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_text = StringIO()\n",
    "sample_data.to_csv(csv_text, index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer ID,Age,Gender,Item Purchased,Category,Purchase Amount (USD),Review Rating,Subscription Status,Payment Method,Discount Applied\n",
      "2472,30.0,Male,Sandals,Footwear,83,4.3,No,,No\n",
      "2015,,Male,Skirt,Clothing,26,3.9,No,,No\n",
      "2792,43.0,Female,Gloves,Accessories,60,2.8,No,Credit Card,No\n",
      "2998,41.0,Female,,Clothing,40,,No,,No\n",
      "621,33.0,Male,Backpack,Accessories,89,3.7,Yes,PayPal,Yes\n",
      "631,41.0,Male,Jewelry,Accessories,94,4.3,Yes,,Yes\n",
      "2268,32.0,,Gloves,Accessories,49,3.8,No,,No\n",
      "1788,,Male,Sweater,Clothing,38,,No,Bank Transfer,No\n",
      "1952,33.0,,Gloves,Accessories,53,,No,Bank Transfer,No\n",
      "2426,58.0,Male,,Footwear,49,3.0,No,Venmo,No\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csv_content = csv_text.getvalue()\n",
    "print(csv_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "model=ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\n",
    "        content='''You are a part of an application you have to perform some tasks.\n",
    "\n",
    "Context: It is an application which gives the quality score for tabular data on the basis of issues listed down.\n",
    "\n",
    "issues = { \n",
    "    \n",
    "    \"column-issues\": {\n",
    "       column1Name:{\n",
    "        \"Duplicated Values\": \"confidence here\",\n",
    "        \"Outliers\": \"confidence here\",\n",
    "        }\n",
    "       column2Name:..........So On.\n",
    "    },\n",
    "    \"cell-issues\": {\n",
    "        column1Name:{\n",
    "        \"Missing Values\": \"confidence here\"\n",
    "        \"Inconsistency\": \"confidence here\"\n",
    "        }\n",
    "       column2Name:..........So On.\n",
    "    }\n",
    "}\n",
    "\n",
    "Confidence: It is basically the value between 0 to 1. And it states that how important the issue is with respect to a dataset. Means If confidence is close to 1 then issue is very important to user, and he don't want to ignore this issue. Means the weightage of issue will be more.\n",
    "\n",
    "Description of issues:\n",
    "\n",
    "Column-Level Issues:\n",
    "1) Duplicated Values: Columns expected to have unique values (e.g., identifiers) but contain duplicates.\n",
    "2) Outliers: Extreme values that are statistically distant from most of the values in the column.\n",
    "\n",
    "Cell-Level Issues:\n",
    "1) Missing Values: Null or empty values where data is expected (e.g., in non-nullable columns).\n",
    "2) Inconsistency: Values that don't conform to expected formats, patterns, or domain constraints. For example, a date column containing a non-date value or a numerical column containing text.\n",
    "\n",
    "Now these issues will have the different confidence score with respect to different columns of different dataset.\n",
    "\n",
    "Task: You have to analyze the given dataset description and the dataset and its columns/features, understand the importance of issues for the given dataset and fill the below format with the confidence score keeping in mind the below given rules for each issues. \n",
    "Rules:\n",
    "    Rules for Duplicate value issue:\n",
    "    Below given features and similar to those will have duplicate value confidence 1\n",
    "        -IDs, Primary Keys, Unique Keys, Identifiers.\n",
    "        -Examples : user_id, order_id, transaction_id, email, but not limited to this.\n",
    "        -These features are crucial for maintaining the uniqueness of records in a dataset.\n",
    "    Below given features and similar to those will have duplicate value confidence 0\n",
    "        -Categorical Features with No Uniqueness Requirement\n",
    "        -Examples : gender, status, education_level, region, but not limited to this.\n",
    "        -These features are used for classification and do not require unique values.\n",
    "    For other features, assign confidence between 0 and 1 based on the importance of Duplicate value issue for that feature. So don't assign 0 and 1 only.\n",
    "\n",
    "    Rules for Missing value issue:\n",
    "    Below given features and similar to those will have missing value confidence 1:\n",
    "        - Features that cannot have null values due to their critical nature in the dataset.\n",
    "        - Examples: IDs, Primary Keys, mandatory fields like created_at, order_id, transaction_id, but not limited to this.\n",
    "        - These are essential features where missing values would affect data integrity.\n",
    "    Below given features and similar to those will have missing value confidence 0:\n",
    "        - Features where missing data is acceptable or does not heavily impact analysis.\n",
    "        - Examples: comments, feedback, review_text, secondary_contact_number, but not limited to this.\n",
    "        - These are optional or free-text fields where null values are expected or permissible.\n",
    "    For other features, assign confidence between 0 and 1 based on the importance of missing values for that feature. So don't assign 0 and 1 only.\n",
    "\n",
    "    Rules for Outlier issue:\n",
    "    Below given features and similar to those will have outlier confidence 1:\n",
    "        - Numeric Features with Defined Ranges, Sensitive Data.\n",
    "        - Examples: salary, age, percentage, transaction_amount, but not limited to this.\n",
    "        - These features must remain within specific thresholds, and outliers could distort analysis or represent errors.\n",
    "    Below given features and similar to those will have outlier confidence 0:\n",
    "        - Features where outliers are either expected or do not significantly impact analysis.\n",
    "        - Examples: gender, education_level, region, feedback, comments, but not limited to this.\n",
    "        - Categorical or free-text fields where there is no concept of outliers.\n",
    "    For other features, assign confidence between 0 and 1 based on the importance of outlier for that feature. So don't assign 0 and 1 only.\n",
    "\n",
    "    Rules for Inconsistency Issue:\n",
    "    Below given features and similar to those will have inconsistency issue confidence 1.\n",
    "        - Features where data must adhere strictly to specific datatype, formats, patterns, or domains.\n",
    "        - Examples: IDs, Primary Keys, Unique Keys, Identifiers, date_of_birth (must follow date format), email (must follow a valid email pattern), phone_number (must follow a valid number pattern), but not limited to this.\n",
    "        - These features have strict requirements for data integrity, and inconsistent values could represent significant errors.\n",
    "    Below given features and similar to those will have inconsistency issue confidence 0.\n",
    "        - Features where there is no strict requirement for format or pattern adherence.\n",
    "        - Examples: comments, feedback, review_text.\n",
    "        - These are free-text or optional fields where data variation is expected, and inconsistency does not significantly affect the analysis.\n",
    "    For other features, assign confidence between 0 and 1 based on the importance of data consistency for that feature. So don't assign 0 and 1 only.\n",
    "\n",
    "Output Format:\n",
    "\n",
    "issues-confidence = { \n",
    "    \n",
    "    \"column-issues\": {\n",
    "       column1Name:{ \n",
    "        \"Duplicated Values\": \"confidence here\",\n",
    "        \"Outliers\": \"confidence here\",\n",
    "        }\n",
    "       column2Name:..........So On.\n",
    "    },\n",
    "    \"cell-issues\": {\n",
    "        column1Name:{ \n",
    "        \"Missing Values\": \"confidence here\"\n",
    "        \"Inconsistency\": \"confidence here\"\n",
    "        }\n",
    "       column2Name:..........So On.\n",
    "    }\n",
    "}\n",
    "\n",
    "Output: \n",
    "Fill the format given above and return it in json. Don't write anything else.\n",
    "\n",
    "'''\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content=f\"\"\"\n",
    "        Data Description: {data_description}\n",
    "        Data: {csv_content}\n",
    "        \"\"\"\n",
    "    )\n",
    "]\n",
    "\n",
    "# Define a chat model and invoke it with the messages\n",
    "result1=model.invoke(messages)\n",
    "result2=model.invoke(messages)\n",
    "result3=model.invoke(messages)\n",
    "result4=model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def LLM_result_to_JSON(result):\n",
    "    cleaned_content = result.content.replace('```json', '').replace('```', '').strip()\n",
    "    issue_confidence = json.loads(cleaned_content)\n",
    "    return issue_confidence\n",
    "\n",
    "issue_confidence1=LLM_result_to_JSON(result1)\n",
    "issue_confidence2=LLM_result_to_JSON(result2)\n",
    "issue_confidence3=LLM_result_to_JSON(result3)\n",
    "issue_confidence4=LLM_result_to_JSON(result4)\n",
    "\n",
    "responses=[issue_confidence1,issue_confidence2,issue_confidence3,issue_confidence4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'column-issues': {'Customer ID': {'Duplicated Values': 1.0, 'Outliers': 0.0},\n",
       "  'Age': {'Duplicated Values': 0.5, 'Outliers': 0.8},\n",
       "  'Gender': {'Duplicated Values': 0.0, 'Outliers': 0.0},\n",
       "  'Item Purchased': {'Duplicated Values': 0.1, 'Outliers': 0.0},\n",
       "  'Category': {'Duplicated Values': 0.0, 'Outliers': 0.0},\n",
       "  'Purchase Amount (USD)': {'Duplicated Values': 0.175,\n",
       "   'Outliers': 0.7750000000000001},\n",
       "  'Review Rating': {'Duplicated Values': 0.2, 'Outliers': 0.55},\n",
       "  'Subscription Status': {'Duplicated Values': 0.0, 'Outliers': 0.0},\n",
       "  'Payment Method': {'Duplicated Values': 0.025, 'Outliers': 0.0},\n",
       "  'Discount Applied': {'Duplicated Values': 0.0, 'Outliers': 0.0}},\n",
       " 'cell-issues': {'Customer ID': {'Missing Values': 0.0, 'Inconsistency': 1.0},\n",
       "  'Age': {'Missing Values': 0.675, 'Inconsistency': 0.3},\n",
       "  'Gender': {'Missing Values': 0.525, 'Inconsistency': 0.05},\n",
       "  'Item Purchased': {'Missing Values': 0.15000000000000002,\n",
       "   'Inconsistency': 0.1},\n",
       "  'Category': {'Missing Values': 0.25, 'Inconsistency': 0.05},\n",
       "  'Purchase Amount (USD)': {'Missing Values': 0.275, 'Inconsistency': 0.3},\n",
       "  'Review Rating': {'Missing Values': 0.4, 'Inconsistency': 0.175},\n",
       "  'Subscription Status': {'Missing Values': 0.0, 'Inconsistency': 0.05},\n",
       "  'Payment Method': {'Missing Values': 0.525, 'Inconsistency': 0.05},\n",
       "  'Discount Applied': {'Missing Values': 0.0, 'Inconsistency': 0.05}}}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def average_responses(responses):\n",
    "    result = {}\n",
    "\n",
    "    num_responses = len(responses)\n",
    "\n",
    "    for response in responses:\n",
    "        for issue_type, columns in response.items():\n",
    "            if issue_type not in result:\n",
    "                result[issue_type] = {}\n",
    "            for column, metrics in columns.items():\n",
    "                if column not in result[issue_type]:\n",
    "                    result[issue_type][column] = {}\n",
    "                for metric, value in metrics.items():\n",
    "                    if metric not in result[issue_type][column]:\n",
    "                        result[issue_type][column][metric] = 0\n",
    "                    result[issue_type][column][metric] += float(value)\n",
    "\n",
    "    # Divide summed values by number of responses to get the average\n",
    "    for issue_type, columns in result.items():\n",
    "        for column, metrics in columns.items():\n",
    "            for metric in metrics:\n",
    "                result[issue_type][column][metric] /= num_responses\n",
    "\n",
    "    return result\n",
    "\n",
    "# Calculate the averaged response\n",
    "issue_confidence = average_responses(responses)\n",
    "issue_confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil import parser\n",
    "\n",
    "def is_valid_string(val):\n",
    "        if isinstance(val, str) and not pd.isnull(val):\n",
    "            try:\n",
    "                float(val)  # Try to convert to float\n",
    "                return False  # If it's a float, return False\n",
    "            except ValueError:\n",
    "                try:\n",
    "            # Try to parse the string as any valid datetime format\n",
    "                    parser.parse(val)\n",
    "                    return False  # It's a valid datetime, so not a valid string\n",
    "                except (ValueError, TypeError):\n",
    "                    return True  # It's not a datetime, so it's a valid string\n",
    "        return False\n",
    "\n",
    "def is_valid_numeric(val):\n",
    "    try:\n",
    "        float(val)  # Try to convert the value to a float\n",
    "        return True  # If conversion succeeds, return True\n",
    "    except (ValueError, TypeError):\n",
    "        return False  # If conversion fails, it's not a valid numeric value\n",
    "\n",
    "def is_valid_datetime(val):\n",
    "    try:\n",
    "        float(val)\n",
    "        return False\n",
    "    except (ValueError, TypeError):\n",
    "        try:\n",
    "        # Attempt to parse the value as a datetime\n",
    "            parser.parse(val)\n",
    "            return True  # If parsing succeeds, it's a valid datetime\n",
    "        except (ValueError, TypeError):\n",
    "            return False  # If parsing fails, it's not a valid datetime\n",
    "\n",
    "def find_column_data_type(column_name):\n",
    "    num_numeric = data[column_name].apply(is_valid_numeric).sum()\n",
    "    num_datetime = data[column_name].apply(is_valid_datetime).sum()\n",
    "    num_string = data[column_name].apply(is_valid_string).sum()\n",
    "    \n",
    "    # Infer type based on the majority of data\n",
    "    if num_numeric > num_string and num_numeric > num_datetime:\n",
    "        return 'numeric'\n",
    "    elif num_datetime > num_string and num_datetime > num_numeric:\n",
    "        return 'datetime'\n",
    "    else:\n",
    "        return 'string'\n",
    "    \n",
    "def is_valid_datatype(row_index, column_name, detected_datatype):\n",
    "    if detected_datatype == 'numeric':\n",
    "        return is_valid_numeric(data.loc[row_index,column_name])\n",
    "    elif detected_datatype == 'datetime':\n",
    "        return is_valid_datetime(data.loc[row_index,column_name])\n",
    "    else:\n",
    "        return is_valid_string(data.loc[row_index,column_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions to find accuracy score corresponding to each issues\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#For column issues\n",
    "\n",
    "def accuracy_score_correspond_to_duplicated_values(column_name):\n",
    "    prevalance=(data[column_name].duplicated().sum())/len(data)\n",
    "    confidence=float(issue_confidence['column-issues'][column_name]['Duplicated Values'])\n",
    "\n",
    "    return float(1-prevalance*confidence)\n",
    "\n",
    "def accuracy_score_correspond_to_outliers(column_name):\n",
    "    if find_column_data_type(column_name)!='numeric':\n",
    "        return float(1-0)\n",
    "    \n",
    "    # Apply the is_valid_numeric function to each element in the column\n",
    "    column = data[column_name].apply(lambda x: x if is_valid_numeric(x) else np.nan)\n",
    "\n",
    "    # Convert the valid numeric entries to float for accurate calculations\n",
    "    column = column.astype(float)\n",
    "\n",
    "    # Now calculate the lower and upper bounds\n",
    "    lowerBound = column.mean() - 3 * column.std()\n",
    "    upperBound = column.mean() + 3 * column.std()\n",
    "\n",
    "    outlier_flags=column.apply(lambda x:x<lowerBound or x>upperBound)\n",
    "\n",
    "    prevalance=outlier_flags.mean()\n",
    "    confidence=float(issue_confidence['column-issues'][column_name]['Outliers'])\n",
    "\n",
    "    return float(1-prevalance*confidence)\n",
    "\n",
    "def accuracy_score_correspond_to_class_imbalance(column_name):\n",
    "    if find_column_data_type(column_name)=='numeric' or find_column_data_type(column_name)=='datetime':\n",
    "        return float(1-0)\n",
    "    \n",
    "    # Get the count of each class in the 'Category' column\n",
    "    class_counts = data[column_name].value_counts()\n",
    "\n",
    "    # Find the minimum and maximum counts\n",
    "    min_count = class_counts.min()\n",
    "    max_count = class_counts.max()\n",
    "\n",
    "    prevalance=(max_count-min_count)/(max_count+min_count)\n",
    "\n",
    "    return float(1-prevalance)\n",
    "\n",
    "\n",
    "#For cell issues\n",
    "\n",
    "def accuracy_score_correspond_to_missing_values(row_name,column_name):\n",
    "    cell_value= data.loc[row_name,column_name]\n",
    "    confidence=float(issue_confidence['cell-issues'][column_name]['Missing Values'])\n",
    "    \n",
    "    if isinstance(cell_value, str):\n",
    "        # For categorical/string values\n",
    "        if cell_value.strip() == \"\":\n",
    "            return float(1 - confidence)\n",
    "    elif isinstance(cell_value, (float, int)):\n",
    "        # For numerical values\n",
    "        if np.isnan(cell_value):\n",
    "            return float(1 - confidence)\n",
    "    elif cell_value is None:\n",
    "        return float(1 - confidence)\n",
    "    return 1\n",
    "\n",
    "def accuracy_score_correspond_to_data_type(row_name,column_name,detected_datatype):\n",
    "    if not (data[column_name].dtype=='object'):\n",
    "        return 1\n",
    "    confidence=float(issue_confidence['cell-issues'][column_name]['Inconsistency'])\n",
    "    if is_valid_datatype(row_name, column_name, detected_datatype):\n",
    "        return 1\n",
    "    return float(1-confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2439/2792475133.py:28: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.16484117948717944' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  final_cell_score_df.at[row_index, column_name] = accuracy_score_column_issue*accuracy_score_cell_issue\n",
      "/tmp/ipykernel_2439/2792475133.py:28: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.45125' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  final_cell_score_df.at[row_index, column_name] = accuracy_score_column_issue*accuracy_score_cell_issue\n",
      "/tmp/ipykernel_2439/2792475133.py:28: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.9006666666666667' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  final_cell_score_df.at[row_index, column_name] = accuracy_score_column_issue*accuracy_score_cell_issue\n",
      "/tmp/ipykernel_2439/2792475133.py:28: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.95' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  final_cell_score_df.at[row_index, column_name] = accuracy_score_column_issue*accuracy_score_cell_issue\n",
      "/tmp/ipykernel_2439/2792475133.py:28: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.8286346153846154' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  final_cell_score_df.at[row_index, column_name] = accuracy_score_column_issue*accuracy_score_cell_issue\n",
      "/tmp/ipykernel_2439/2792475133.py:28: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.8013846153846154' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  final_cell_score_df.at[row_index, column_name] = accuracy_score_column_issue*accuracy_score_cell_issue\n",
      "/tmp/ipykernel_2439/2792475133.py:28: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.9750448717948718' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  final_cell_score_df.at[row_index, column_name] = accuracy_score_column_issue*accuracy_score_cell_issue\n"
     ]
    }
   ],
   "source": [
    "# Create an empty DataFrame to store the final scores\n",
    "final_cell_score_df = pd.DataFrame(1, index=data.index, columns=data.columns)\n",
    "\n",
    "issues_scores={}\n",
    "# Loop over each column in the DataFrame\n",
    "for column_name in data.columns:\n",
    "    issues_scores[column_name]={}\n",
    "    column_detected_dtype= find_column_data_type(column_name)\n",
    "    column_score_duplicates=0\n",
    "    column_score_outliers=0\n",
    "    column_score_class_imbalance=0\n",
    "    column_score_missing=0\n",
    "    column_score_datatype=0\n",
    "    # Dealing column specific issues\n",
    "    score_duplicates = accuracy_score_correspond_to_duplicated_values(column_name)\n",
    "    score_outliers = accuracy_score_correspond_to_outliers(column_name)\n",
    "    score_class_imbalance = accuracy_score_correspond_to_class_imbalance(column_name)\n",
    "    accuracy_score_column_issue = score_duplicates*score_outliers\n",
    "   \n",
    "    # Now, loop over each row in this column\n",
    "    for row_index in data.index:\n",
    "        # Dealing cell specific issues\n",
    "        score_missing = accuracy_score_correspond_to_missing_values(row_index,column_name)\n",
    "        score_datatype = accuracy_score_correspond_to_data_type(row_index,column_name,column_detected_dtype)\n",
    "        accuracy_score_cell_issue = score_missing*score_datatype\n",
    "       \n",
    "        # Assign the final score for this cell\n",
    "        final_cell_score_df.at[row_index, column_name] = accuracy_score_column_issue*accuracy_score_cell_issue\n",
    "\n",
    "        column_score_missing=column_score_missing+score_missing\n",
    "        column_score_datatype=column_score_datatype+score_datatype\n",
    "    issues_scores[column_name]['duplicates']=round(score_duplicates*100,2)\n",
    "    issues_scores[column_name]['outliers']=round(score_outliers*100,2)\n",
    "    issues_scores[column_name]['imbalance']=round(score_class_imbalance*100,2)\n",
    "    issues_scores[column_name]['missing']=round((column_score_missing/len(data))*100,2)\n",
    "    issues_scores[column_name]['datatype']=round((column_score_datatype/len(data))*100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Item Purchased</th>\n",
       "      <th>Category</th>\n",
       "      <th>Purchase Amount (USD)</th>\n",
       "      <th>Review Rating</th>\n",
       "      <th>Subscription Status</th>\n",
       "      <th>Payment Method</th>\n",
       "      <th>Discount Applied</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.164841</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.900667</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.828635</td>\n",
       "      <td>0.801385</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975045</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.507204</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.689010</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.828635</td>\n",
       "      <td>0.480831</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975045</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.164841</td>\n",
       "      <td>0.45125</td>\n",
       "      <td>0.900667</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.828635</td>\n",
       "      <td>0.480831</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975045</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.507204</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.900667</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.828635</td>\n",
       "      <td>0.480831</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975045</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.507204</td>\n",
       "      <td>0.45125</td>\n",
       "      <td>0.900667</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.828635</td>\n",
       "      <td>0.801385</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975045</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0.355043</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.900667</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.828635</td>\n",
       "      <td>0.801385</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975045</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0.507204</td>\n",
       "      <td>0.45125</td>\n",
       "      <td>0.900667</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.828635</td>\n",
       "      <td>0.801385</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975045</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0.507204</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.900667</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.828635</td>\n",
       "      <td>0.801385</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975045</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0.507204</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.900667</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.828635</td>\n",
       "      <td>0.480831</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975045</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0.507204</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.900667</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.828635</td>\n",
       "      <td>0.480831</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975045</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Customer ID       Age   Gender  Item Purchased  Category  \\\n",
       "0            1  0.164841  1.00000        0.900667      1.00   \n",
       "1            1  0.507204  1.00000        0.689010      1.00   \n",
       "2            1  0.164841  0.45125        0.900667      1.00   \n",
       "3            1  0.507204  1.00000        0.900667      0.95   \n",
       "4            1  0.507204  0.45125        0.900667      1.00   \n",
       "5            1  0.355043  1.00000        0.900667      1.00   \n",
       "6            1  0.507204  0.45125        0.900667      1.00   \n",
       "7            1  0.507204  1.00000        0.900667      1.00   \n",
       "8            1  0.507204  1.00000        0.900667      1.00   \n",
       "9            1  0.507204  1.00000        0.900667      1.00   \n",
       "\n",
       "   Purchase Amount (USD)  Review Rating  Subscription Status  Payment Method  \\\n",
       "0               0.828635       0.801385                    1        0.975045   \n",
       "1               0.828635       0.480831                    1        0.975045   \n",
       "2               0.828635       0.480831                    1        0.975045   \n",
       "3               0.828635       0.480831                    1        0.975045   \n",
       "4               0.828635       0.801385                    1        0.975045   \n",
       "5               0.828635       0.801385                    1        0.975045   \n",
       "6               0.828635       0.801385                    1        0.975045   \n",
       "7               0.828635       0.801385                    1        0.975045   \n",
       "8               0.828635       0.480831                    1        0.975045   \n",
       "9               0.828635       0.480831                    1        0.975045   \n",
       "\n",
       "   Discount Applied  \n",
       "0                 1  \n",
       "1                 1  \n",
       "2                 1  \n",
       "3                 1  \n",
       "4                 1  \n",
       "5                 1  \n",
       "6                 1  \n",
       "7                 1  \n",
       "8                 1  \n",
       "9                 1  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_cell_score_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Issues_scores {'Customer ID': {'duplicates': 100.0, 'outliers': 100.0, 'imbalance': 100.0, 'missing': 100.0, 'datatype': 100.0}, 'Age': {'duplicates': 50.73, 'outliers': 99.98, 'imbalance': 100.0, 'missing': 93.25, 'datatype': 99.98}, 'Gender': {'duplicates': 100.0, 'outliers': 100.0, 'imbalance': 64.62, 'missing': 89.5, 'datatype': 99.0}, 'Item Purchased': {'duplicates': 90.07, 'outliers': 100.0, 'imbalance': 82.31, 'missing': 97.75, 'datatype': 98.5}, 'Category': {'duplicates': 100.0, 'outliers': 100.0, 'imbalance': 0.12, 'missing': 100.0, 'datatype': 100.0}, 'Purchase Amount (USD)': {'duplicates': 82.86, 'outliers': 100.0, 'imbalance': 100.0, 'missing': 100.0, 'datatype': 100.0}, 'Review Rating': {'duplicates': 80.14, 'outliers': 100.0, 'imbalance': 100.0, 'missing': 88.0, 'datatype': 100.0}, 'Subscription Status': {'duplicates': 100.0, 'outliers': 100.0, 'imbalance': 54.0, 'missing': 100.0, 'datatype': 100.0}, 'Payment Method': {'duplicates': 97.5, 'outliers': 100.0, 'imbalance': 92.42, 'missing': 86.87, 'datatype': 98.75}, 'Discount Applied': {'duplicates': 100.0, 'outliers': 100.0, 'imbalance': 86.0, 'missing': 100.0, 'datatype': 100.0}}\n",
      "Column Score :  {'Customer ID': 1.0, 'Age': 0.4728893528933395, 'Gender': 0.89025, 'Item Purchased': 0.8689181666666664, 'Category': 0.9999871794871794, 'Purchase Amount (USD)': 0.8286346153846155, 'Review Rating': 0.7052184615384612, 'Subscription Status': 1.0, 'Payment Method': 0.8412809034455127, 'Discount Applied': 1.0}\n",
      "Data Score :  86.07178679415773\n"
     ]
    }
   ],
   "source": [
    "column_score = final_cell_score_df.mean(numeric_only=True).to_dict()\n",
    "data_score = final_cell_score_df.values.flatten().mean()\n",
    "\n",
    "print('Issues_scores',issues_scores)\n",
    "print('Column Score : ',column_score)\n",
    "print('Data Score : ',data_score*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
